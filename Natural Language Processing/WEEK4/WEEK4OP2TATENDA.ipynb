{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JAhlo17ADRYh",
        "outputId": "b7e7926e-2838-47ac-b7f7-2e2aba9e1961"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tweepy in /usr/local/lib/python3.11/dist-packages (4.14.0)\n",
            "Requirement already satisfied: oauthlib<4,>=3.2.0 in /usr/local/lib/python3.11/dist-packages (from tweepy) (3.2.2)\n",
            "Requirement already satisfied: requests<3,>=2.27.0 in /usr/local/lib/python3.11/dist-packages (from tweepy) (2.32.3)\n",
            "Requirement already satisfied: requests-oauthlib<2,>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from tweepy) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27.0->tweepy) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27.0->tweepy) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27.0->tweepy) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27.0->tweepy) (2024.12.14)\n"
          ]
        }
      ],
      "source": [
        "!pip install tweepy\n",
        "from google.colab import userdata"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tweepy\n",
        "import time"
      ],
      "metadata": {
        "id": "5PxnWnulEwiK"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Get API KEY, SECRET AND BEARER TOKEN from the X Developer portal free tier: https://developer.x.com/"
      ],
      "metadata": {
        "id": "bxoYB3IlDbda"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Twitter API credentials\n",
        "\n",
        "bearer_token = userdata.get('XBEARER')\n"
      ],
      "metadata": {
        "id": "QY5E9ZU9Do9M"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Authenticate with the Twitter API using Bearer Token\n"
      ],
      "metadata": {
        "id": "31-uBSSRIuaI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "client = tweepy.Client(bearer_token=bearer_token)\n"
      ],
      "metadata": {
        "id": "jsngTJLmEfqs"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define search parameters"
      ],
      "metadata": {
        "id": "sZlKRLQqIwio"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"DeepSeek AI lang:en -is:retweet\"  # Search for English tweets, excluding retweets\n",
        "max_results = 100  # Fetch up to 100 tweets per request (API limit)\n"
      ],
      "metadata": {
        "id": "2xx9VXitE0Zp"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Function to handle API rate limits and fetch tweets\n"
      ],
      "metadata": {
        "id": "SxyFHbfrI1on"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def fetch_tweets_with_retry(query, max_results, retries=3):\n",
        "    \"\"\"\n",
        "    Fetch tweets from the X API with rate-limit handling.\n",
        "    Args:\n",
        "        query (str): The search query string.\n",
        "        max_results (int): Maximum number of tweets per request.\n",
        "        retries (int): Number of retries in case of rate limiting.\n",
        "    Returns:\n",
        "        list: List of fetched tweets.\n",
        "    \"\"\"\n",
        "    attempt = 0\n",
        "    while attempt < retries:\n",
        "        try:\n",
        "            # Fetch recent tweets\n",
        "            response = client.search_recent_tweets(\n",
        "                query=query,\n",
        "                max_results=max_results,\n",
        "                tweet_fields=[\"created_at\", \"text\", \"author_id\", \"public_metrics\", \"entities\"]\n",
        "            )\n",
        "            return response.data if response.data else []\n",
        "        except tweepy.errors.TooManyRequests:\n",
        "            attempt += 1\n",
        "            wait_time = 15 * 60  # Wait 15 minutes before retrying\n",
        "            print(f\"Rate limit reached. Retrying in {wait_time // 60} minutes...\")\n",
        "            time.sleep(wait_time)\n",
        "    print(\"Max retries reached. Exiting.\")\n",
        "    return []"
      ],
      "metadata": {
        "id": "K_0eDH9TE-mM"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Fetch tweets"
      ],
      "metadata": {
        "id": "LvAz_76iI51-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(f\"Fetching tweets about '{query}'...\\n\")\n",
        "tweets = fetch_tweets_with_retry(query, max_results)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dV12oX2lFMQu",
        "outputId": "ccb2c7b4-2d96-47d1-eb1e-0e626d25f6ed"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fetching tweets about 'DeepSeek AI lang:en -is:retweet'...\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "if tweets:\n",
        "    # Sort tweets by retweet count in descending order\n",
        "    sorted_tweets = sorted(tweets, key=lambda x: x.public_metrics[\"retweet_count\"], reverse=True)\n",
        "\n",
        "    # Get the top 15 tweets\n",
        "    top_tweets = sorted_tweets[:15]\n",
        "\n",
        "    print(f\"Top 15 Tweets about '{query}' by Retweets:\\n\")\n",
        "    for i, tweet in enumerate(top_tweets, start=1):\n",
        "        print(f\"{i}. Tweet ID: {tweet.id}\")\n",
        "        print(f\"   Author ID: {tweet.author_id}\")\n",
        "        print(f\"   Created At: {tweet.created_at}\")\n",
        "        print(f\"   Retweets: {tweet.public_metrics['retweet_count']}\")\n",
        "        print(f\"   Text: {tweet.text}\")\n",
        "        print(f\"   Mentions: {tweet.entities.get('mentions', []) if tweet.entities else 'None'}\")\n",
        "        print(\"-\" * 80)\n",
        "else:\n",
        "    print(\"No tweets found or rate limit exceeded.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FJn8i5fOFGti",
        "outputId": "3e621f00-f5cd-4ad6-b60d-8de92a2e2c80"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 15 Tweets about 'DeepSeek AI lang:en -is:retweet' by Retweets:\n",
            "\n",
            "1. Tweet ID: 1884371370773209108\n",
            "   Author ID: 1814726379805814787\n",
            "   Created At: 2025-01-28 22:41:59+00:00\n",
            "   Retweets: 1\n",
            "   Text: @BillAckman @deepseek_ai @nvidia I went to China. They have humans inside their ATM cash machines. It could be like that with DeepSeek, human PHD's answering every request, lol.\n",
            "   Mentions: [{'start': 0, 'end': 11, 'username': 'BillAckman', 'id': '880412538625810432'}, {'start': 12, 'end': 24, 'username': 'deepseek_ai', 'id': '1714580962569588736'}, {'start': 25, 'end': 32, 'username': 'nvidia', 'id': '61559439'}]\n",
            "--------------------------------------------------------------------------------\n",
            "2. Tweet ID: 1884371202334212243\n",
            "   Author ID: 2962828127\n",
            "   Created At: 2025-01-28 22:41:19+00:00\n",
            "   Retweets: 1\n",
            "   Text: @iamjasonlevin supposedly research on this already and the answer is that yes, yes you can. \n",
            "\n",
            "With deepseek R1 this accuracy is probably closer to 90% versus the 70% a year'ish ago.\n",
            "\n",
            "With neuralink, we'll be able to read brain scans/thinking without x-rays\n",
            "\n",
            "https://t.co/VZ3dYql4Cj\n",
            "   Mentions: [{'start': 0, 'end': 14, 'username': 'iamjasonlevin', 'id': '362189690'}]\n",
            "--------------------------------------------------------------------------------\n",
            "3. Tweet ID: 1884371548720562268\n",
            "   Author ID: 1883878569585065985\n",
            "   Created At: 2025-01-28 22:42:41+00:00\n",
            "   Retweets: 0\n",
            "   Text: @CookerFlips Trading is like AI development - patience and strategy over quick gains. At DeepSeek, we don't rush breakthroughs. Same applies here. Hold your position, let the tech (and trades) mature. $WENFENG holders know this well.\n",
            "   Mentions: [{'start': 0, 'end': 12, 'username': 'CookerFlips', 'id': '1189381231198134272'}]\n",
            "--------------------------------------------------------------------------------\n",
            "4. Tweet ID: 1884371548552774134\n",
            "   Author ID: 241458274\n",
            "   Created At: 2025-01-28 22:42:41+00:00\n",
            "   Retweets: 0\n",
            "   Text: @FortuneMagazine Trump is going to ban DeepSeek because it has undone his Stargate AI Project capture\n",
            "   Mentions: [{'start': 0, 'end': 16, 'username': 'FortuneMagazine', 'id': '25053299'}]\n",
            "--------------------------------------------------------------------------------\n",
            "5. Tweet ID: 1884371547470569814\n",
            "   Author ID: 534653770\n",
            "   Created At: 2025-01-28 22:42:41+00:00\n",
            "   Retweets: 0\n",
            "   Text: Remember that @deepseek_ai is just a propaganda tool of Chinese totalitarianism. https://t.co/yltcqGq4r5\n",
            "   Mentions: [{'start': 14, 'end': 26, 'username': 'deepseek_ai', 'id': '1714580962569588736'}]\n",
            "--------------------------------------------------------------------------------\n",
            "6. Tweet ID: 1884371545159786543\n",
            "   Author ID: 1631519610892693504\n",
            "   Created At: 2025-01-28 22:42:40+00:00\n",
            "   Retweets: 0\n",
            "   Text: Overarching framework:\n",
            "\n",
            "DeepSeekâ€™s new V3 and R1 models show that GenAI can become more cost-efficientâ€”great news for software vendors building AI solutions (rather than selling the models themselves). Lower â€œinput costsâ€ should drive higher usage  and accelerate adoption acrossâ€¦ https://t.co/nZrpG03Y0m\n",
            "   Mentions: []\n",
            "--------------------------------------------------------------------------------\n",
            "7. Tweet ID: 1884371542311637370\n",
            "   Author ID: 21353169\n",
            "   Created At: 2025-01-28 22:42:40+00:00\n",
            "   Retweets: 0\n",
            "   Text: Thank you @compass_mining for publishing my latest article which highlights the impact and benefits of the recent announcement by @deepseek_ai, to the North American #HPC and #AI industry. https://t.co/EutN6DjY5j\n",
            "   Mentions: [{'start': 10, 'end': 25, 'username': 'compass_mining', 'id': '1072307787894419456'}, {'start': 130, 'end': 142, 'username': 'deepseek_ai', 'id': '1714580962569588736'}]\n",
            "--------------------------------------------------------------------------------\n",
            "8. Tweet ID: 1884371541078491165\n",
            "   Author ID: 1428625460922142723\n",
            "   Created At: 2025-01-28 22:42:39+00:00\n",
            "   Retweets: 0\n",
            "   Text: @MuslimV0ice @SubboorAhmad @deepseek_ai All you need is location data for the scenario.\n",
            "   Mentions: [{'start': 0, 'end': 12, 'username': 'MuslimV0ice', 'id': '1705987749587652608'}, {'start': 13, 'end': 26, 'username': 'SubboorAhmad', 'id': '1257436560'}, {'start': 27, 'end': 39, 'username': 'deepseek_ai', 'id': '1714580962569588736'}]\n",
            "--------------------------------------------------------------------------------\n",
            "9. Tweet ID: 1884371537987330146\n",
            "   Author ID: 753512826\n",
            "   Created At: 2025-01-28 22:42:39+00:00\n",
            "   Retweets: 0\n",
            "   Text: When the whole world is amused about Chinaâ€™s #DeepSeek , few chapris are searching about Arunachal Pradesh and worried about AI botâ€™s unresponsive towards it!! #ChinaAI #china #deepseekai #ArunachalPradesh\n",
            "   Mentions: []\n",
            "--------------------------------------------------------------------------------\n",
            "10. Tweet ID: 1884371530500411559\n",
            "   Author ID: 1742940673836195840\n",
            "   Created At: 2025-01-28 22:42:37+00:00\n",
            "   Retweets: 0\n",
            "   Text: @RenatusAI @deepseek_ai DeepSeek really took everyone by surprise yesterday, and now @RenatusAI is doing the same for the web3 community! I gotta try the bot out and see how it improved ðŸ‘€\n",
            "   Mentions: [{'start': 0, 'end': 10, 'username': 'RenatusAI', 'id': '1867518928659820544'}, {'start': 11, 'end': 23, 'username': 'deepseek_ai', 'id': '1714580962569588736'}, {'start': 85, 'end': 95, 'username': 'RenatusAI', 'id': '1867518928659820544'}]\n",
            "--------------------------------------------------------------------------------\n",
            "11. Tweet ID: 1884371527770222724\n",
            "   Author ID: 1862275368171782144\n",
            "   Created At: 2025-01-28 22:42:36+00:00\n",
            "   Retweets: 0\n",
            "   Text: @BillAckman @deepseek_ai @nvidia What are the chances??????? 10000000% that was a nasty short play. But I bet you and everyone else rode it too. Itâ€™s a nasty game Iâ€™m not hating ðŸ¤·â€â™‚ï¸\n",
            "   Mentions: [{'start': 0, 'end': 11, 'username': 'BillAckman', 'id': '880412538625810432'}, {'start': 12, 'end': 24, 'username': 'deepseek_ai', 'id': '1714580962569588736'}, {'start': 25, 'end': 32, 'username': 'nvidia', 'id': '61559439'}]\n",
            "--------------------------------------------------------------------------------\n",
            "12. Tweet ID: 1884371524595114445\n",
            "   Author ID: 1296622091605643266\n",
            "   Created At: 2025-01-28 22:42:36+00:00\n",
            "   Retweets: 0\n",
            "   Text: @luke_leisher_ @Astrolavey @BSF42069 The censourship isn't the open source Ai itself, it's just the deepseek app. The ai could be implimented without it\n",
            "   Mentions: [{'start': 0, 'end': 14, 'username': 'luke_leisher_', 'id': '1839268922463498240'}, {'start': 15, 'end': 26, 'username': 'Astrolavey', 'id': '1186544769520033792'}, {'start': 27, 'end': 36, 'username': 'BSF42069', 'id': '1661739003987759109'}]\n",
            "--------------------------------------------------------------------------------\n",
            "13. Tweet ID: 1884371498820948400\n",
            "   Author ID: 1586150448918052864\n",
            "   Created At: 2025-01-28 22:42:29+00:00\n",
            "   Retweets: 0\n",
            "   Text: Ok so, \n",
            "Chinaâ€™s AI DeepSeek\n",
            "ITS FOS\n",
            "Nothing but Chicom propaganda \n",
            "\n",
            "Thats it https://t.co/vm0EKAu9AV\n",
            "   Mentions: []\n",
            "--------------------------------------------------------------------------------\n",
            "14. Tweet ID: 1884371494018416661\n",
            "   Author ID: 1474833903894638605\n",
            "   Created At: 2025-01-28 22:42:28+00:00\n",
            "   Retweets: 0\n",
            "   Text: $BABA build a better ai than deepseek and is sitting on a mountain of cash\n",
            "   Mentions: []\n",
            "--------------------------------------------------------------------------------\n",
            "15. Tweet ID: 1884371493187887183\n",
            "   Author ID: 1844920810533720068\n",
            "   Created At: 2025-01-28 22:42:28+00:00\n",
            "   Retweets: 0\n",
            "   Text: @BillAckman @deepseek_ai @nvidia If they didn't make a fortune... they are idiots.\n",
            "   Mentions: [{'start': 0, 'end': 11, 'username': 'BillAckman', 'id': '880412538625810432'}, {'start': 12, 'end': 24, 'username': 'deepseek_ai', 'id': '1714580962569588736'}, {'start': 25, 'end': 32, 'username': 'nvidia', 'id': '61559439'}]\n",
            "--------------------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " Save Results to CSV"
      ],
      "metadata": {
        "id": "CRGnFPl3JKU3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Save the top 15 tweets to a CSV file if data exists\n",
        "if tweets:\n",
        "    tweet_data = [\n",
        "        {\n",
        "            \"Tweet ID\": tweet.id,\n",
        "            \"Author ID\": tweet.author_id,\n",
        "            \"Created At\": tweet.created_at,\n",
        "            \"Text\": tweet.text,\n",
        "            \"Retweets\": tweet.public_metrics[\"retweet_count\"],\n",
        "            \"Mentions\": tweet.entities.get(\"mentions\", []) if tweet.entities else \"None\"\n",
        "        }\n",
        "        for tweet in top_tweets\n",
        "    ]\n",
        "\n",
        "    # Convert to DataFrame\n",
        "    df = pd.DataFrame(tweet_data)\n",
        "\n",
        "    # Save to CSV\n",
        "    output_file = \"top_15_deepseek_ai_tweets.csv\"\n",
        "    df.to_csv(output_file, index=False)\n",
        "    print(f\"Data saved to {output_file}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3jamGb0CIbW6",
        "outputId": "bdee8693-c1d4-4eb9-a657-726e044d715a"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data saved to top_15_deepseek_ai_tweets.csv\n"
          ]
        }
      ]
    }
  ]
}